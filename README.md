# CS433 Machine Learning Project 1 - Group Project

Welcome to the CS433 Machine Learning Project 1 repository. This repository contains the code for the first project of
the CS433 Machine Learning course at EPFL. The goal of this project is to implement various machine learning algorithms
to predict the label of a dataset.

## Table of Contents

1. [Introduction](#introduction)
2. [Setting up the Dataset](#setting-up-the-dataset)
3. [Running the Scripts](#running-the-scripts)
4. [Project Structure](#project-structure)
5. [Contributors](#contributors)

---

## Introduction

This project is a part of the CS433 Machine Learning course at EPFL. The goal of this project is to implement various
machine learning algorithms to predict the label of a dataset. You will find different scripts in this repository to
help you prepare the dataset, train models, and evaluate their performance.

## Setting up the Dataset

Before you begin, you need to set up the dataset. Make sure to download the dataset files to the `material/data`
directory.

```shell
mkdir "material/data"
```

Respectively :

- `x_train.csv`
- `y_train.csv`
- `x_test.csv`

## Running the Scripts

We have several scripts available to perform different tasks for the project. Below is a brief description of each
script and how to run them:

Please ensure that you have the necessary dependencies installed before running the scripts by executing the following
command:

```shell
pip install -r requirements.txt
```

You also need to run all previous scripts before running the next one (except for the whole pipeline and the run_tests
scripts).

0. **run.py** - This script is for running the whole pipeline. It performs the following tasks:
    - Prepare the datasets
    - Run cross-validation
    - Train the final model
    - Evaluate the final model
   ```shell
   python run.py
   ```

1. **run_prepare_datasets.py** - Execute this script to prepare the datasets. Use the following command:
   ```shell
   python run_prepare_datasets.py
   ```

2. **run_cross_validation.py** - Use this script for running cross-validation on your models. Run it as follows:
   ```shell
   python run_cross_validation.py
   ```

3. **run_final_training.py** - This script is for training the final model. Run it using the command:
   ```shell
   python run_final_training.py
   ```
4. **run_evaluate_final_model.py** - To evaluate the final model, execute the following command:
   ```shell
   python run_evaluate_final_model.py
   ```


6. **run_tests.py** - To run tests for the project, use the following command:
   ```shell
   python run_tests.py
   ```

## Project Structure

The project has a specific directory structure, and it's essential to understand it. Here's an overview of the project
structure:

```
CS433-ML-Project1/
│
├── material/  # Dataset and other project materials
│   ├── data/  # Put your dataset files here, not tracked by Git.
│   ├── grading_tests/ # Grading tests 
│   └── helpers.py
│
├── output/  # Output directory (not tracked by Git, generated by scripts)
│   ├── datasets/ # Prepared datasets .npy files
│   ├── cross_validation/ # Cross-validation results .pickle files (plots)
│   ├── final_training/ # Final model weights w.npy file (plots)
│   └── final_evaluation/ # Final model evaluation (plots, submission.csv)
│
├── .gitignore
├── README.md # This file
├── exponential_lr.py # Exponential learning rate class
├── hyperparameters.py # Hyperparameters (which can be changed)
├── implementations.py # Implementations of the ML algorithms
├── run.py # Run the whole pipeline
├── run_tests.py # Run tests 
├── run_prepare_datasets.py # Prepare the datasets
├── run_cross_validation.py # Run cross-validation
├── run_final_training.py # Train the final model
├── run_evaluate_final_model.py # Evaluate the final model
└── requirements.txt # Python dependencies
```

The `output/` directory is where various project outputs will be stored, such as the prepared datasets, cross-validation
results, final model weights, and final model evaluation.
Plots are saved as `.png` files, and other files are saved as `.npy` or `.pickle` files.

## Contributors

- [Zaghouane Fares](https://github.com/faresZzz)
